import React, { useRef, useEffect } from "react";
import * as cocoSsd from "@tensorflow-models/coco-ssd"; // Ù…ÙƒØªØ¨Ø© Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡
import "@tensorflow/tfjs"; // Ù„Ø§Ø²Ù… Ù‡Ø°Ø§ Ø­ØªÙ‰ ÙŠØ´ØªØºÙ„ cocoSsd

const getColorForClass = (className: string): string => {
  const colorMap: { [key: string]: string } = {
    person: "#00FF00",
    bottle: "#007BFF",
    chair: "#FF5733",
    tv: "#FFC107",
    book: "#9C27B0",
    // ğŸ‘‡ ØªØ¶ÙŠÙ Ø£Ù†ÙˆØ§Ø¹ Ø£Ø®Ø±Ù‰ Ø­Ø³Ø¨ Ø§Ù„Ø­Ø§Ø¬Ø©
  };

  // Ù„Ùˆ Ø§Ù„Ù†ÙˆØ¹ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯ØŒ Ù†Ø±Ø¬Ø¹ Ù„ÙˆÙ† Ø¹Ø´ÙˆØ§Ø¦ÙŠ
  if (!colorMap[className]) {
    colorMap[className] = getRandomColor();
  }

  return colorMap[className];
};

// ğŸ² ØªÙˆÙ„ÙŠØ¯ Ù„ÙˆÙ† Ø¹Ø´ÙˆØ§Ø¦ÙŠ ÙÙŠ Ø­Ø§Ù„Ø© Ù…Ø§ ÙƒØ§Ù†Ø´ Ø§Ù„Ù†ÙˆØ¹ Ù…ÙˆØ¬ÙˆØ¯
const getRandomColor = (): string => {
  const letters = "0123456789ABCDEF";
  let color = "#";
  for (let i = 0; i < 6; i++) {
    color += letters[Math.floor(Math.random() * 16)];
  }
  return color;
};

const ObjectDetection: React.FC = () => {
  const videoRef = useRef<HTMLVideoElement | null>(null); // ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
  const canvasRef = useRef<HTMLCanvasElement | null>(null); // ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ÙƒØ§Ù†ÙØ§Ø³

  // âºï¸ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
  const startCamera = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: true,
        audio: false,
      });
      const devices = await navigator.mediaDevices.enumerateDevices();
      console.log("Devices:", devices);
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
      }
    } catch (err) {
      console.error("Error accessing camera:", err);
    }
  };

  // ğŸ§  ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙˆØ§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡
  const runObjectDetection = async () => {
    const model = await cocoSsd.load(); // ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„

    const detectFrame = async () => {
      const video = videoRef.current;
      if (video && video.readyState === 4) {
        const predictions = await model.detect(video);

        drawPredictions(predictions); // ÙŠØ±Ø³Ù… Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª
        requestAnimationFrame(detectFrame); // ÙŠØ¹ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„ ÙƒÙ„ ÙØ±ÙŠÙ…
      }
    };

    detectFrame(); // Ø£ÙˆÙ„ Ù†Ø¯Ø§Ø¡
  };

  // ğŸ¨ Ø±Ø³Ù… Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø¹Ù„Ù‰ Ø§Ù„ÙƒØ§Ù†ÙØ§Ø³
  const drawPredictions = (predictions: cocoSsd.DetectedObject[]) => {
    const canvas = canvasRef.current;
    const video = videoRef.current;

    if (!canvas || !video) return;

    const ctx = canvas.getContext("2d");
    if (!ctx) return;

    // Ø¶Ø¨Ø· Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ÙƒØ§Ù†ÙØ§Ø³
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;

    ctx.clearRect(0, 0, canvas.width, canvas.height);

    predictions.forEach((prediction) => {
      const [x, y, width, height] = prediction.bbox;

      // ğŸ§ª ØªÙˆÙ„ÙŠØ¯ Ù„ÙˆÙ† ÙØ±ÙŠØ¯ Ø­Ø³Ø¨ Ø§Ø³Ù… Ø§Ù„ÙƒØ§Ø¦Ù†
      const color = getColorForClass(prediction.class);

      // Ø±Ø³Ù… Ø§Ù„Ù…Ø³ØªØ·ÙŠÙ„
      ctx.strokeStyle = color;
      ctx.lineWidth = 2;
      ctx.strokeRect(x, y, width, height);

      // Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø³Ø¨Ø©
      const confidence = (prediction.score * 100).toFixed(1);

      // Ø±Ø³Ù… Ø§Ù„Ù†Øµ
      ctx.fillStyle = color;
      ctx.font = "16px Arial";
      ctx.fillText(
        `${prediction.class} (${confidence}%)`,
        x,
        y > 10 ? y - 5 : 10 // Ø­Ø¯Ø¯ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø°ÙŠ Ø³ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù†Øµ
      );
    });
  };
  useEffect(() => {
    startCamera();
    runObjectDetection();
  }, []);

  return (
    <div style={{ position: "relative" }}>
      {/* Ø§Ù„ÙÙŠØ¯ÙŠÙˆ */}
      <video
        ref={videoRef}
        autoPlay
        playsInline
        muted
        style={{ width: "100%", maxWidth: "720px" }}
      />

      {/* Ø§Ù„ÙƒØ§Ù†ÙØ§Ø³ */}
      <canvas
        ref={canvasRef}
        style={{
          position: "absolute",
          top: 0,
          left: 0,
        }}
      />
    </div>
  );
};

export default ObjectDetection;
